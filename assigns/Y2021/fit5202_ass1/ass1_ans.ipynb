{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents<a class=\"anchor\" id=\"table\"></a>\n",
    "\n",
    "* [1 Working with RDD](#1)\n",
    "* [1.1 Data Preparation and Loading](#1.1)\n",
    "* [1.1.1 Creating SparkSession & SparkContext](#OneOneOne)\n",
    "* [1.1.2 Read CSV files, Preprocessing, and final(formatted data) RDD for each file](#OneOneTwo)\n",
    "* [1.1.2.1 Flights RDD](#1.1.2.1)\n",
    "* [1.1.2.2 Airports RDD](#1.1.2.2)\n",
    "* [1.1.3 Show RDD number of columns, and number of records](#1.1.3)\n",
    "* [1.2 Dataset flights partitioning](#1.2)\n",
    "* [1.2.1 Obtain the maximum arrival time ](#1.2.1)\n",
    "* [1.2.2 Obtain the maximum minimum time ](#1.2.2)\n",
    "* [1.2.3 Define hash partitioning](#1.2.3)\n",
    "* [1.2.4 Display the records in each partition](#1.2.4)\n",
    "* [1.3 Query RDD](#1.3)\n",
    "* [1.3.1 Collect a total number of flights for each month for all flights](#1.3.1)\n",
    "* [1.3.2 Collect the average delay for each month for all flights](#1.3.2)\n",
    "* [2 Working with DataFrames](#2)\n",
    "* [2.1 Data Preparation and Loading](#2.1)\n",
    "* [2.1.1 Define DataFrames](#2.1.1)\n",
    "* [2.1.2 Display the Scheme of DataFrames](#2.1.2)\n",
    "* [2.1.3 Transform date-time and location column](#2.1.3)\n",
    "* [2.2.1 January Flights Events with ANC airport](#2.2.1)\n",
    "* [2.2.2 Average Arrival Delay From Origin to Destination](#2.2.2)\n",
    "* [2.2.3 Join Query with Airports DataFrame](#2.2.3)\n",
    "* [2.3 Analysis](#2.3.1)\n",
    "* [2.3.1 Relationship between day of week with mean arrival delay, total time delay, and count flights](#2.3.1)\n",
    "* [2.3.2 Display mean arrival delay each month](#2.3.2)\n",
    "* [2.3.3 Relationship between mean departure delay and mean arrival delay](#2.3.3)\n",
    "* [3 RDDs vs DataFrame vs Spark SQL](#3)\n",
    "* [3.1 RDD Operation](#3.1)\n",
    "* [3.2 DataFrame Operation](#3.1)\n",
    "* [3.3 Spark SQL Operation](#3.1)\n",
    "* [3.4 Discussion](#3.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 1 Working with RDD<a class=\"anchor\" id=\"1\"></a>\n",
    "## 1.1 Data Preparation and Loading<a class=\"anchor\" id=\"1.1\"></a>\n",
    "### 1.1.1 Create SparkSession and SparkContext<a class=\"anchor\" id=\"OneOneOne\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.rdd import RDD\n",
    "\n",
    "master = \"local[*]\"\n",
    "app_name = \"Assignment1\"\n",
    "spark_conf = SparkConf().setMaster(master).setAppName(app_name)\n",
    "\n",
    "spark = SparkSession.builder.config(conf=spark_conf).getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Import CSV files and Make RDD for each file<a class=\"anchor\" id=\"OneOneTwo\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define funtion that reads file and load into rdd object\n",
    "def read_file_rdd(file):\n",
    "    rdd=sc.textFile(file)\n",
    "    #remove the header\n",
    "    header=rdd.first()\n",
    "    rdd=rdd.filter(lambda row: row!=header)\n",
    "    return rdd\n",
    "\n",
    "def transtype(rows):\n",
    "    rows=rows.split(\",\")\n",
    "    return rows\n",
    "\n",
    "# trans flights columns \n",
    "def transtype_flights(rows):\n",
    "    rows=rows.split(\",\")\n",
    "    rows[0]=int(rows[0])\n",
    "    rows[1]=int(rows[1])\n",
    "    rows[2]=int(rows[2])\n",
    "    rows[3]=int(rows[3])\n",
    "    rows[5]=int(rows[5])\n",
    "    if(rows[11]!=''):\n",
    "        rows[11]=float(rows[11])\n",
    "    else:\n",
    "        rows[11]=0\n",
    "    if rows[12]!='':\n",
    "        rows[12]=float(rows[12])\n",
    "    else:\n",
    "        rows[12]=0\n",
    "    if(rows[15]!=''):\n",
    "        rows[15]=float(rows[15])\n",
    "    else:\n",
    "        rows[15]=0\n",
    "    if(rows[16]!=''):\n",
    "        rows[16]=float(rows[16])\n",
    "    else:\n",
    "        rows[16]=0\n",
    "    if(rows[17]!=''):\n",
    "        rows[17]=float(rows[17])\n",
    "    else:\n",
    "        rows[17]=0.0\n",
    "    if(rows[19]!=''):\n",
    "        rows[19]=float(rows[19])\n",
    "    else:\n",
    "        rows[19]=0\n",
    "#     if(rows[21]!=''):\n",
    "#         rows[21]=float(rows[21])\n",
    "#     else:\n",
    "#         rows[21]=0\n",
    "    if(rows[22]!=''):\n",
    "        rows[22]=float(rows[22])\n",
    "    else:\n",
    "        rows[22]=0\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2.1 Flights RDD <a class=\"anchor\" id=\"1.1.2.1\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partitions of flights:20\n"
     ]
    }
   ],
   "source": [
    "# Read the 20 files of “flight*.csv” file into a single RDD (flights_rdd) \n",
    "flights_rdd=read_file_rdd(\"flight*.csv\")\n",
    "\n",
    "flights_rdd=flights_rdd.map(transtype_flights)\n",
    "\n",
    "print(flights_rdd.take(3))\n",
    "print(flights_rdd.count())\n",
    "\n",
    "print(\"Number of partitions of flights:{}\".format(flights_rdd.getNumPartitions()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2.2 Airports RDD <a class=\"anchor\" id=\"1.1.2.2\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ABE,Lehigh Valley International Airport,Allentown,PA,USA,40.65236,-75.44040', 'ABI,Abilene Regional Airport,Abilene,TX,USA,32.41132,-99.68190', 'ABQ,Albuquerque International Sunport,Albuquerque,NM,USA,35.04022,-106.60919']\n",
      "\n",
      "Number of partitions of airports:2\n"
     ]
    }
   ],
   "source": [
    "# read file airports.csv into airports_rdd\n",
    "airports_rdd=read_file_rdd(\"airports.csv\")\n",
    "print(airports_rdd.take(3))\n",
    "print()\n",
    "\n",
    "print(\"Number of partitions of airports:{}\".format(airports_rdd.getNumPartitions()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Show RDD number of columns, and number of records <a class=\"anchor\" id=\"1.1.3\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of columns of airports_rdd: 7\n",
      "number of columns of flights_rdd: 31\n",
      "number of records of airports_rdd:  322\n",
      "number of records of flights_rdd:  582184\n"
     ]
    }
   ],
   "source": [
    "def num_of_columns(rdd):\n",
    "    return len(rdd.take(1)[0])\n",
    "\n",
    "\n",
    "# number of columns of airports_rdd\n",
    "airports_columns=num_of_columns(airports_rdd.map(transtype))\n",
    "print('number of columns of airports_rdd: {}'.format(airports_columns))\n",
    "\n",
    "# number of columns of fights_rdd\n",
    "flights_columns=num_of_columns(flights_rdd)\n",
    "print('number of columns of flights_rdd: {}'.format(flights_columns))\n",
    "\n",
    "\n",
    "# total number of records of airports_rdd\n",
    "total_airports_records=airports_rdd.count()\n",
    "print('number of records of airports_rdd: ',total_airports_records)\n",
    "\n",
    "# total number of records of flights_rdd\n",
    "total_flights_records=flights_rdd.count()\n",
    "print('number of records of flights_rdd: ',total_flights_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Dataset Partitioning <a class=\"anchor\" id=\"1.2\"></a>\n",
    "### 1.2.1 Obtain the maximum arrival time <a class=\"anchor\" id=\"1.2.1\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2015, 9, 13, 7, 'AA', 1063, 'N3CAAA', 'SAN', 'DFW', '700', '1050', 1670.0, 26.0, '1116', '179', 174.0, 142.0, 1171.0, '1538', 6.0, '1159', '1544', 1665.0, '0', '0', '', '0', '0', '1665', '0', '0']\n",
      " maximum arrival delay is 1665.0\n"
     ]
    }
   ],
   "source": [
    "# flights_rdd.filter(lambda x:x[21]==max(x[21]))\n",
    "\n",
    "maximum_arrival_time=flights_rdd.max(key=lambda x:x[22])\n",
    "print(maximum_arrival_time)\n",
    "print(\" maximum arrival delay is {}\".format(maximum_arrival_time[22]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Obtain the minimum arrival time <a class=\"anchor\" id=\"1.2.2\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2015, 1, 21, 3, 'AS', 11, 'N467AS', 'EWR', 'SEA', '1720', '1705', -15.0, 13.0, '1718', '389', 322.0, 305.0, 2402.0, '1923', 4.0, '2049', '1927', -82.0, '0', '0', '', '', '', '', '', '']\n",
      " minimum arrival delay is -82.0\n"
     ]
    }
   ],
   "source": [
    "minimum_arrival_time=flights_rdd.min(key=lambda x:x[22])\n",
    "print(minimum_arrival_time)\n",
    "print(\" minimum arrival delay is {}\".format(minimum_arrival_time[22]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Define hash partitioning function <a class=\"anchor\" id=\"1.2.3\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hash Function to implement Hash Partitioning \n",
    "\n",
    "def hash_function(k):\n",
    "    total = 0\n",
    "    for digit in str(k):\n",
    "        total += int(digit)\n",
    "    return total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4 Display the records in each partition <a class=\"anchor\" id=\"1.2.4\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partitions:20\n",
      "Partitioner:None\n"
     ]
    }
   ],
   "source": [
    "from pyspark.rdd import RDD\n",
    "#A Function to print the data items in each RDD\n",
    "#WARNING: this function is only for demo purpose, it should not be used on large dataset\n",
    "def print_partitions(data):\n",
    "    if isinstance(data, RDD):\n",
    "        numPartitions = data.getNumPartitions()\n",
    "        partitions = data.glom().collect()\n",
    "    else:\n",
    "        numPartitions = data.rdd.getNumPartitions()\n",
    "        partitions = data.rdd.glom().collect()\n",
    "    \n",
    "    print(f\"####### NUMBER OF PARTITIONS: {numPartitions}\")\n",
    "    for index, partition in enumerate(partitions):\n",
    "        # show partition if it is not empty\n",
    "        if len(partition) > 0:\n",
    "            print(f\"Partition {index}: {len(partition)} records\")\n",
    "            print(partition)\n",
    "# hash partitioning\n",
    "no_of_partitions=40\n",
    "# flights_hash_partitioned_rdd = flights_rdd.partitionBy(no_of_partitions, hash_function)\n",
    "# flights_hash_partitioned_rdd.collect()\n",
    "\n",
    "print(\"Number of partitions:{}\".format(flights_rdd.getNumPartitions()))\n",
    "print(\"Partitioner:{}\".format(flights_rdd.partitioner))\n",
    "# print_partitions(flights_rdd)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Query RDD  <a class=\"anchor\" id=\"1.3\"></a>\n",
    "### 1.3.1 Collect a total number of flights for each month <a class=\"anchor\" id=\"1.3.1\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {6: 50256,\n",
       "             12: 47866,\n",
       "             1: 47136,\n",
       "             11: 46809,\n",
       "             4: 48810,\n",
       "             8: 50524,\n",
       "             7: 52065,\n",
       "             10: 48680,\n",
       "             3: 50816,\n",
       "             5: 49691,\n",
       "             9: 46733,\n",
       "             2: 42798})"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_rdd.map(lambda x:(x[1],x[5])).countByKey()\n",
    "\n",
    "# flights_rdd.map(lambda x:(x[0],x[1],x[5])).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Collect the average delay for each month <a class=\"anchor\" id=\"1.3.2\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 5.652155465037339], [2, 7.722627225571288], [3, 4.889286838790932], [4, 3.1355050194632246], [5, 4.644402406874485], [6, 9.534662527857371], [7, 6.701373283395755], [8, 4.652501781331645], [9, -0.8448847709327456], [10, -0.5383935907970419], [11, 0.8206114208805999], [12, 6.035244223457151]]\n"
     ]
    }
   ],
   "source": [
    "# flights_rdd.map(lambda x:(x[1],x[22])).collect()\n",
    "\n",
    "# print(flights_rdd.collect())\n",
    "# reduceByKey(func, [numPartitions])\n",
    "\n",
    "seqOp = (lambda x, y: (x[0] + y, x[1] + 1))\n",
    "combOp = (lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
    "\n",
    "avgdelay_rdd=flights_rdd.map(lambda x:(x[1],x[22])).aggregateByKey((0,0),seqOp,combOp).map(lambda x: [x[0],x[1][0]/x[1][1]])\n",
    "print(avgdelay_rdd.collect())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Working with DataFrame <a class=\"anchor\" id=\"2\"></a>\n",
    "## 2.1. Data Preparation and Loading <a class=\"anchor\" id=\"2.1\"></a>\n",
    "### 2.1.1 Define dataframes and loading scheme<a class=\"anchor\" id=\"2.1.1\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load all flights and airports data into two separate dataframes. Name the dataframes as flightsDf and airportsDf respectively.\n",
    "# Hint : use the module spark.read.format(“csv”), with header option is true and inferSchema is true\n",
    "airportsDf= spark.read.format('csv')\\\n",
    "            .option('header',True).option('escape','\"')\\\n",
    "            .load('airports.csv')\n",
    "\n",
    "flightsDf= spark.read.format('csv').option('header',True).option('escape','\"').load('flight*.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Display the schema of the final two dataframes<a class=\"anchor\" id=\"2.1.2\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- IATA_CODE: string (nullable = true)\n",
      " |-- AIRPORT: string (nullable = true)\n",
      " |-- CITY: string (nullable = true)\n",
      " |-- STATE: string (nullable = true)\n",
      " |-- COUNTRY: string (nullable = true)\n",
      " |-- LATITUDE: string (nullable = true)\n",
      " |-- LONGITUDE: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- YEAR: string (nullable = true)\n",
      " |-- MONTH: string (nullable = true)\n",
      " |-- DAY: string (nullable = true)\n",
      " |-- DAY_OF_WEEK: string (nullable = true)\n",
      " |-- AIRLINE: string (nullable = true)\n",
      " |-- FLIGHT_NUMBER: string (nullable = true)\n",
      " |-- TAIL_NUMBER: string (nullable = true)\n",
      " |-- ORIGIN_AIRPORT: string (nullable = true)\n",
      " |-- DESTINATION_AIRPORT: string (nullable = true)\n",
      " |-- SCHEDULED_DEPARTURE: string (nullable = true)\n",
      " |-- DEPARTURE_TIME: string (nullable = true)\n",
      " |-- DEPARTURE_DELAY: string (nullable = true)\n",
      " |-- TAXI_OUT: string (nullable = true)\n",
      " |-- WHEELS_OFF: string (nullable = true)\n",
      " |-- SCHEDULED_TIME: string (nullable = true)\n",
      " |-- ELAPSED_TIME: string (nullable = true)\n",
      " |-- AIR_TIME: string (nullable = true)\n",
      " |-- DISTANCE: string (nullable = true)\n",
      " |-- WHEELS_ON: string (nullable = true)\n",
      " |-- TAXI_IN: string (nullable = true)\n",
      " |-- SCHEDULED_ARRIVAL: string (nullable = true)\n",
      " |-- ARRIVAL_TIME: string (nullable = true)\n",
      " |-- ARRIVAL_DELAY: string (nullable = true)\n",
      " |-- DIVERTED: string (nullable = true)\n",
      " |-- CANCELLED: string (nullable = true)\n",
      " |-- CANCELLATION_REASON: string (nullable = true)\n",
      " |-- AIR_SYSTEM_DELAY: string (nullable = true)\n",
      " |-- SECURITY_DELAY: string (nullable = true)\n",
      " |-- AIRLINE_DELAY: string (nullable = true)\n",
      " |-- LATE_AIRCRAFT_DELAY: string (nullable = true)\n",
      " |-- WEATHER_DELAY: string (nullable = true)\n",
      "\n",
      "+---------+--------------------+-----------+-----+-------+--------+----------+\n",
      "|IATA_CODE|             AIRPORT|       CITY|STATE|COUNTRY|LATITUDE| LONGITUDE|\n",
      "+---------+--------------------+-----------+-----+-------+--------+----------+\n",
      "|      ABE|Lehigh Valley Int...|  Allentown|   PA|    USA|40.65236| -75.44040|\n",
      "|      ABI|Abilene Regional ...|    Abilene|   TX|    USA|32.41132| -99.68190|\n",
      "|      ABQ|Albuquerque Inter...|Albuquerque|   NM|    USA|35.04022|-106.60919|\n",
      "|      ABR|Aberdeen Regional...|   Aberdeen|   SD|    USA|45.44906| -98.42183|\n",
      "|      ABY|Southwest Georgia...|     Albany|   GA|    USA|31.53552| -84.19447|\n",
      "+---------+--------------------+-----------+-----+-------+--------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n",
      "|YEAR|MONTH|DAY|DAY_OF_WEEK|AIRLINE|FLIGHT_NUMBER|TAIL_NUMBER|ORIGIN_AIRPORT|DESTINATION_AIRPORT|SCHEDULED_DEPARTURE|DEPARTURE_TIME|DEPARTURE_DELAY|TAXI_OUT|WHEELS_OFF|SCHEDULED_TIME|ELAPSED_TIME|AIR_TIME|DISTANCE|WHEELS_ON|TAXI_IN|SCHEDULED_ARRIVAL|ARRIVAL_TIME|ARRIVAL_DELAY|DIVERTED|CANCELLED|CANCELLATION_REASON|AIR_SYSTEM_DELAY|SECURITY_DELAY|AIRLINE_DELAY|LATE_AIRCRAFT_DELAY|WEATHER_DELAY|\n",
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n",
      "|2015|    6| 26|          5|     EV|         4951|     N707EV|           BHM|                LGA|                630|           629|             -1|      13|       642|           155|         141|     113|     866|      935|     15|             1005|         950|          -15|       0|        0|               null|            null|          null|         null|               null|         null|\n",
      "|2015|   12| 19|          6|     WN|         3589|     N764SW|           MKE|                DCA|               1630|          1627|             -3|      13|      1640|           115|          96|      79|     634|     1859|      4|             1925|        1903|          -22|       0|        0|               null|            null|          null|         null|               null|         null|\n",
      "|2015|    1| 10|          6|     WN|         3370|     N720WN|           SNA|                OAK|               1055|          1054|             -1|      11|      1105|            85|          80|      63|     371|     1208|      6|             1220|        1214|           -6|       0|        0|               null|            null|          null|         null|               null|         null|\n",
      "|2015|   11|  1|          7|     WN|         2081|     N461WN|           PDX|                LAS|               1345|          1346|              1|       9|      1355|           120|         115|      97|     763|     1532|      9|             1545|        1541|           -4|       0|        0|               null|            null|          null|         null|               null|         null|\n",
      "|2015|    6| 11|          4|     WN|          836|     N8628A|           BNA|                BOS|               1635|          1627|             -8|      12|      1639|           150|         149|     127|     942|     1946|     10|             2005|        1956|           -9|       0|        0|               null|            null|          null|         null|               null|         null|\n",
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2.Display the schema of the final of two dataframes\n",
    "\n",
    "#display the schema of dataframe: airports_df\n",
    "airportsDf.printSchema()\n",
    "#display the schema of dataframe: flights_df\n",
    "flightsDf.printSchema()\n",
    "\n",
    "#\n",
    "#display the rows of the dataframe\n",
    "airportsDf.show(5)\n",
    "flightsDf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Query Analysis <a class=\"anchor\" id=\"2.2\"></a>\n",
    "### 2.2.1 January flight events with ANC airport <a class=\"anchor\" id=\"2.2.1\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+-------------------+--------+-------------+\n",
      "|MONTH|ORIGIN_AIRPORT|DESTINATION_AIRPORT|DISTANCE|ARRIVAL_DELAY|\n",
      "+-----+--------------+-------------------+--------+-------------+\n",
      "|    1|           ANC|                SEA|    1448|          -13|\n",
      "|    1|           ANC|                SEA|    1448|           -4|\n",
      "|    1|           ANC|                JNU|     571|           17|\n",
      "|    1|           ANC|                CDV|     160|           20|\n",
      "|    1|           ANC|                BET|     399|          -20|\n",
      "|    1|           ANC|                SEA|    1448|          -15|\n",
      "|    1|           ANC|                SEA|    1448|          -11|\n",
      "|    1|           ANC|                ADQ|     253|          -16|\n",
      "|    1|           ANC|                SEA|    1448|           17|\n",
      "|    1|           ANC|                BET|     399|           -9|\n",
      "|    1|           ANC|                SEA|    1448|           15|\n",
      "|    1|           ANC|                FAI|     261|           -6|\n",
      "|    1|           ANC|                JNU|     571|            2|\n",
      "|    1|           ANC|                JNU|     571|           -3|\n",
      "|    1|           ANC|                PDX|    1542|          -21|\n",
      "|    1|           ANC|                SEA|    1448|           -5|\n",
      "|    1|           ANC|                SEA|    1448|          -15|\n",
      "|    1|           ANC|                PDX|    1542|          -13|\n",
      "|    1|           ANC|                SFO|    2018|           20|\n",
      "|    1|           ANC|                FAI|     261|           56|\n",
      "+-----+--------------+-------------------+--------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1.Display all the flight events in January 2015 with five columns (Month, Origin Airport, Destination Airport, Distance, and Arrival Delay), \n",
    "# where the origin airport 'ANC' and name this dataframe as janFlightEventsAncDf.\n",
    "\n",
    "janFlightEventAncDf=flightsDf.filter(flightsDf.YEAR==2015).filter(flightsDf.MONTH==1).filter(flightsDf.ORIGIN_AIRPORT=='ANC').select(\"MONTH\",\"ORIGIN_AIRPORT\",\"DESTINATION_AIRPORT\",\"DISTANCE\",\"ARRIVAL_DELAY\")\n",
    "janFlightEventAncDf.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Average Arrival Delay From Origin to Destination <a class=\"anchor\" id=\"2.2.2\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+-------------+\n",
      "|ORIGIN_AIRPORT|DESTINATION_AIRPORT|AVERAGE_DELAY|\n",
      "+--------------+-------------------+-------------+\n",
      "|           ANC|                ADK|     -27.0000|\n",
      "|           ANC|                HNL|     -20.0000|\n",
      "|           ANC|                MSP|     -19.2500|\n",
      "|           ANC|                BET|      -9.0909|\n",
      "|           ANC|                SEA|      -6.4902|\n",
      "|           ANC|                BRW|      -4.3333|\n",
      "|           ANC|                OME|      -3.0000|\n",
      "|           ANC|                ADQ|      -2.6667|\n",
      "|           ANC|                CDV|       1.0000|\n",
      "|           ANC|                OTZ|       1.2500|\n",
      "|           ANC|                PHX|       2.0000|\n",
      "|           ANC|                DEN|       3.3333|\n",
      "|           ANC|                PDX|       3.5000|\n",
      "|           ANC|                JNU|       5.0000|\n",
      "|           ANC|                LAS|       9.0000|\n",
      "|           ANC|                SCC|      16.6667|\n",
      "|           ANC|                SFO|      20.0000|\n",
      "|           ANC|                FAI|      25.0000|\n",
      "+--------------+-------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2.From the query results on query no.1, please display a new query. Then please group by ‘ORIGIN_AIRPORT’ AND ‘DESTINATION_AIRPORT’.\n",
    "# Add a new column and name it as ‘AVERAGE_DELAY’. This column value is the average from all‘ARRIVAL_DELAY’ values. \n",
    "# Then sort it based on ‘AVERAGE_DELAY’. Please name this dataframe as janFlightEventsAncAvgDf.\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "# from pyspark.sql.types import DecimalType\n",
    "janFlightEventAncDf=janFlightEventAncDf.withColumn(\"ARRIVAL_DELAY\",janFlightEventAncDf[\"ARRIVAL_DELAY\"].cast(T.DecimalType()))\n",
    "janFlightEventsAncAvgDf=janFlightEventAncDf.groupby(['ORIGIN_AIRPORT','DESTINATION_AIRPORT'])\\\n",
    ".agg(F.avg('ARRIVAL_DELAY').alias('AVERAGE_DELAY'))\n",
    "janFlightEventsAncAvgDf=janFlightEventsAncAvgDf.orderBy(janFlightEventsAncAvgDf.AVERAGE_DELAY)\n",
    "janFlightEventsAncAvgDf.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Join Query with Airports DataFrame <a class=\"anchor\" id=\"2.2.3\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+-------------+---------+--------------------+---------+-----+-------+--------+----------+\n",
      "|ORIGIN_AIRPORT|DESTINATION_AIRPORT|AVERAGE_DELAY|IATA_CODE|             AIRPORT|     CITY|STATE|COUNTRY|LATITUDE| LONGITUDE|\n",
      "+--------------+-------------------+-------------+---------+--------------------+---------+-----+-------+--------+----------+\n",
      "|           ANC|                BRW|      -4.3333|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                ADK|     -27.0000|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                OME|      -3.0000|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                JNU|       5.0000|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                LAS|       9.0000|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                SCC|      16.6667|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                CDV|       1.0000|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                DEN|       3.3333|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                OTZ|       1.2500|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                SFO|      20.0000|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                FAI|      25.0000|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                ADQ|      -2.6667|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                PDX|       3.5000|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                PHX|       2.0000|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                HNL|     -20.0000|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                SEA|      -6.4902|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                MSP|     -19.2500|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                BET|      -9.0909|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "+--------------+-------------------+-------------+---------+--------------------+---------+-----+-------+--------+----------+\n",
      "\n",
      "+--------------+-------------------+-------------+---------+--------------------+-------------+-----+-------+--------+----------+\n",
      "|ORIGIN_AIRPORT|DESTINATION_AIRPORT|AVERAGE_DELAY|IATA_CODE|             AIRPORT|         CITY|STATE|COUNTRY|LATITUDE| LONGITUDE|\n",
      "+--------------+-------------------+-------------+---------+--------------------+-------------+-----+-------+--------+----------+\n",
      "|           ANC|                BRW|      -4.3333|      BRW|Wiley Post-Will R...|       Barrow|   AK|    USA|71.28545|-156.76600|\n",
      "|           ANC|                ADK|     -27.0000|      ADK|        Adak Airport|         Adak|   AK|    USA|51.87796|-176.64603|\n",
      "|           ANC|                OME|      -3.0000|      OME|        Nome Airport|         Nome|   AK|    USA|64.51220|-165.44525|\n",
      "|           ANC|                JNU|       5.0000|      JNU|Juneau Internatio...|       Juneau|   AK|    USA|58.35496|-134.57628|\n",
      "|           ANC|                LAS|       9.0000|      LAS|McCarran Internat...|    Las Vegas|   NV|    USA|36.08036|-115.15233|\n",
      "|           ANC|                SCC|      16.6667|      SCC|Deadhorse Airport...|    Deadhorse|   AK|    USA|70.19476|-148.46516|\n",
      "|           ANC|                CDV|       1.0000|      CDV|Merle K. (Mudhole...|      Cordova|   AK|    USA|60.49183|-145.47765|\n",
      "|           ANC|                DEN|       3.3333|      DEN|Denver Internatio...|       Denver|   CO|    USA|39.85841|-104.66700|\n",
      "|           ANC|                OTZ|       1.2500|      OTZ|Ralph Wien Memori...|     Kotzebue|   AK|    USA|66.88468|-162.59855|\n",
      "|           ANC|                SFO|      20.0000|      SFO|San Francisco Int...|San Francisco|   CA|    USA|37.61900|-122.37484|\n",
      "|           ANC|                FAI|      25.0000|      FAI|Fairbanks Interna...|    Fairbanks|   AK|    USA|64.81368|-147.85967|\n",
      "|           ANC|                ADQ|      -2.6667|      ADQ|      Kodiak Airport|       Kodiak|   AK|    USA|57.74997|-152.49386|\n",
      "|           ANC|                PDX|       3.5000|      PDX|Portland Internat...|     Portland|   OR|    USA|45.58872|-122.59750|\n",
      "|           ANC|                PHX|       2.0000|      PHX|Phoenix Sky Harbo...|      Phoenix|   AZ|    USA|33.43417|-112.00806|\n",
      "|           ANC|                HNL|     -20.0000|      HNL|Honolulu Internat...|     Honolulu|   HI|    USA|21.31869|-157.92241|\n",
      "|           ANC|                SEA|      -6.4902|      SEA|Seattle-Tacoma In...|      Seattle|   WA|    USA|47.44898|-122.30931|\n",
      "|           ANC|                MSP|     -19.2500|      MSP|Minneapolis-Saint...|  Minneapolis|   MN|    USA|44.88055| -93.21692|\n",
      "|           ANC|                BET|      -9.0909|      BET|      Bethel Airport|       Bethel|   AK|    USA|60.77978|-161.83800|\n",
      "+--------------+-------------------+-------------+---------+--------------------+-------------+-----+-------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3.Join the results on query no. 2 janFlightEventsAncAvgDf and airportsDf using inner join operation. You may name this dataset as joinedSqlDf.\n",
    "\n",
    "# inner join using janFlightEventsAncAvgDf.ORIGIN_AIRPORT==airportsDf.IATA_CODE\n",
    "joinedSqlDf=janFlightEventsAncAvgDf.join(airportsDf, janFlightEventsAncAvgDf.ORIGIN_AIRPORT==airportsDf.IATA_CODE)\n",
    "joinedSqlDf.show()\n",
    "\n",
    "# inner join using janFlightEventsAncAvgDf.DESTINATION_AIRPORT==airportsDf.IATA_CODE\n",
    "joinedSqlDf=janFlightEventsAncAvgDf.join(airportsDf, janFlightEventsAncAvgDf.DESTINATION_AIRPORT==airportsDf.IATA_CODE)\n",
    "joinedSqlDf.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Analysis <a class=\"anchor\" id=\"2.3\"></a>\n",
    "### 2.3.1 Relationship between day of week with mean arrival delay, total time delay, and count flights <a class=\"anchor\" id=\"2.3.1\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+--------------+------------+\n",
      "|DAY_OF_WEEK| MeanArrivalDelay|TotalTimeDelay|NumOfFlights|\n",
      "+-----------+-----------------+--------------+------------+\n",
      "|          4|6.036164255716286|      129355.0|       21819|\n",
      "|          5|4.501339698933113|       92399.0|       20826|\n",
      "|          3|5.863307196723768|      117401.0|       20434|\n",
      "|          2|6.848719138188753|      132872.0|       20180|\n",
      "|          1|9.925783642336173|      178277.0|       19136|\n",
      "|          7|9.933103249928099|      172687.0|       18149|\n",
      "|          6|3.747166885363235|       62825.0|       17256|\n",
      "+-----------+-----------------+--------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  1. Find the total number of flights events, total time delay and average of arrival delay for each day of week (‘DAY_OF_WEEK’) \n",
    "# sorted by the value of NumOfFlights in descending order. This query represents the summary of all 2015 flights. \n",
    "# What can you analyse from this query results?\n",
    "\n",
    "# create views from dataframe\n",
    "airportsDf.createOrReplaceTempView(\"sql_airports\")\n",
    "flightsDf.createOrReplaceTempView(\"sql_flights\")\n",
    "\n",
    "# \n",
    "sql_flights_query=spark.sql('''\n",
    "select DAY_OF_WEEK, avg(ARRIVAL_DELAY) as MeanArrivalDelay, sum(ARRIVAL_DELAY) as TotalTimeDelay,count(*) as NumOfFlights\n",
    "from sql_flights\n",
    "where YEAR=2015 and MONTH in ('12','1','2')\n",
    "group by DAY_OF_WEEK\n",
    "order by NumOfFlights desc\n",
    "''')\n",
    "sql_flights_query.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Display mean arrival delay each month <a class=\"anchor\" id=\"2.3.2\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+--------------+------------+\n",
      "|MONTH|   MeanArrivalDelay|TotalTimeDelay|NumOfFlights|\n",
      "+-----+-------------------+--------------+------------+\n",
      "|    9|-0.8498676252179341|      -39484.0|       46733|\n",
      "|   10| -0.541989784312509|      -26209.0|       48680|\n",
      "|   11| 0.8313745860658399|       38412.0|       46809|\n",
      "|    4|  3.173803944339603|      153044.0|       48810|\n",
      "|    5| 4.7121097658084405|      230785.0|       49691|\n",
      "|    8|  4.713893233866763|      235063.0|       50524|\n",
      "|    3|  5.011173860427592|      248454.0|       50816|\n",
      "|    1|  5.804357298474946|      266420.0|       47136|\n",
      "|   12|   6.15837046195826|      288883.0|       47866|\n",
      "|    7|  6.786093552465234|      348907.0|       52065|\n",
      "|    2|  8.123906203913085|      330513.0|       42798|\n",
      "|    6|  9.747630090727856|      479174.0|       50256|\n",
      "+-----+-------------------+--------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Find the average of arrival delay, total time delay, and total number of flight events for each month (‘MONTH’) sorted by MeanArrivalDelay in ascending order (default).\n",
    "# What can you analyse from this query results?\n",
    "\n",
    "sql_flights_query2=spark.sql('''\n",
    "select MONTH, avg(ARRIVAL_DELAY) as MeanArrivalDelay, sum(ARRIVAL_DELAY) as TotalTimeDelay,count(*) as NumOfFlights\n",
    "from sql_flights\n",
    "group by MONTH\n",
    "order by MeanArrivalDelay \n",
    "''')\n",
    "sql_flights_query2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Relationship between mean departure delay and mean arrival delay <a class=\"anchor\" id=\"2.3.3\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+-------------------+\n",
      "|MONTH|     MeanDeptDelay|   MeanArrivalDelay|\n",
      "+-----+------------------+-------------------+\n",
      "|    6|  13.9730063585922|  9.747630090727856|\n",
      "|   12|11.821651454043728|   6.15837046195826|\n",
      "|    7|11.708608758020432|  6.786093552465234|\n",
      "|    2|11.620796080832823|  8.123906203913085|\n",
      "|    8|10.086906141367324|  4.713893233866763|\n",
      "|    1|  9.75401499511029|  5.804357298474946|\n",
      "|    3| 9.718308159530178|  5.011173860427592|\n",
      "|    5| 9.550310180006102| 4.7121097658084405|\n",
      "|    4| 7.737554783759199|  3.173803944339603|\n",
      "|   11| 6.630585898709037| 0.8313745860658399|\n",
      "|   10| 5.243436261558784| -0.541989784312509|\n",
      "|    9| 4.728506981740065|-0.8498676252179341|\n",
      "+-----+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3.Display the mean departure delay (MeanDeptDelay) and mean arrival delay (MeanArrivalDelay) for each month (‘MONTH’) sorted by MeanDeptDelay in\n",
    "# descending order. What you can analyse from the relationship between two columns: Mean Departure Delay and Mean Arrival Delay?\n",
    "\n",
    "sql_flights_query3=spark.sql('''\n",
    "select MONTH,avg(DEPARTURE_DELAY) as MeanDeptDelay,avg(ARRIVAL_DELAY) as MeanArrivalDelay\n",
    "from sql_flights\n",
    "group by MONTH\n",
    "order by MeanDeptDelay desc\n",
    "''')\n",
    "sql_flights_query3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 RDDs vs DataFrame vs Spark SQL <a class=\"anchor\" id=\"3\"></a>\n",
    "\n",
    "\n",
    "Implement the following queries using RDDs, DataFrames and SparkSQL separately. Log the time taken for each query in each approach using the “%%time” built-in magic command in Jupyter Notebook and discuss the performance difference of these 3 approaches.\n",
    "\n",
    "<strong>Find the MONTH and DAY_OF_WEEK, number of flights, and average delay where TAIL_NUMBER = ‘N407AS’. Note number of flights and average delay should be aggregated separately. The average delay should be grouped by both MONTH and DAYS_OF_WEEK.</strong>\n",
    "\n",
    "## 3.1 RDD Operation<a class=\"anchor\" id=\"3.1\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(1, 1), -6.0, 1], [(1, 2), 17.5, 2], [(1, 3), -27.0, 1], [(1, 5), -21.0, 2], [(1, 6), 4.333333333333333, 3], [(2, 1), -2.5, 2], [(2, 2), -9.5, 2], [(2, 3), -11.5, 2], [(2, 4), -11.0, 2], [(2, 5), -31.0, 1], [(2, 7), 6.5, 2], [(3, 1), 29.0, 1], [(3, 2), -28.0, 2], [(3, 3), 3.0, 1], [(3, 4), 2.0, 1], [(3, 5), 6.666666666666667, 3], [(3, 6), -3.0, 1], [(4, 1), 0.0, 1], [(4, 2), 6.0, 1], [(4, 3), -7.0, 1], [(4, 4), -0.6666666666666666, 3], [(4, 6), -20.0, 1], [(4, 7), -22.0, 1], [(5, 1), 4.666666666666667, 3], [(5, 2), 0.8, 5], [(5, 3), 30.0, 1], [(5, 5), 6.0, 1], [(5, 6), -3.0, 2], [(5, 7), -7.666666666666667, 3], [(6, 1), 7.0, 4], [(6, 2), 35.0, 1], [(6, 3), -10.666666666666666, 3], [(6, 4), -15.0, 1], [(6, 6), -7.666666666666667, 3], [(7, 1), -1.0, 1], [(7, 3), -5.333333333333333, 3], [(7, 4), -4.0, 2], [(7, 5), -4.0, 1], [(7, 7), 15.2, 5], [(8, 1), -13.0, 2], [(8, 2), -11.0, 2], [(8, 3), -4.0, 1], [(8, 4), -5.0, 1], [(8, 5), -10.0, 3], [(8, 6), -5.0, 2], [(8, 7), 60.5, 2], [(9, 1), -15.5, 2], [(9, 2), -10.0, 1], [(9, 3), -14.6, 5], [(9, 4), -10.666666666666666, 3], [(9, 5), 5.0, 1], [(10, 1), 15.5, 2], [(10, 3), 1.0, 2], [(10, 4), -6.0, 1], [(10, 5), -3.6666666666666665, 3], [(11, 1), 35.0, 1], [(11, 2), -23.0, 1], [(11, 4), -1.0, 2], [(11, 5), 12.0, 1], [(11, 7), -4.0, 3], [(12, 1), -1.0, 1], [(12, 2), -11.5, 2], [(12, 3), 18.5, 2], [(12, 4), 6.0, 1], [(12, 5), 2.0, 2], [(12, 7), -1.0, 2]]\n",
      "CPU times: user 89.9 ms, sys: 30.3 ms, total: 120 ms\n",
      "Wall time: 8.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# print(flights_rdd.filter(lambda x: 'N407AS' in x).count())\n",
    "rdd=flights_rdd.filter(lambda x: 'N407AS' in x).map(lambda x :[(x[1],x[3]),x[22]])\n",
    "\n",
    "\n",
    "seqOp = (lambda x, y: (x[0] + y, x[1] + 1))\n",
    "combOp = (lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
    "rdd=rdd.aggregateByKey((0,0),seqOp,combOp)\n",
    "\n",
    "rdd=rdd.map(lambda x : [x[0],x[1][0]/x[1][1], x[1][1]])\n",
    "print(rdd.sortBy(lambda x: x[0]).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 DataFrame Operation<a class=\"anchor\" id=\"3.2\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+-------------------+------------+\n",
      "|MONTH|DAY_OF_WEEK|   MeanArrivalDelay|NumOfFlights|\n",
      "+-----+-----------+-------------------+------------+\n",
      "|    1|          1|               -6.0|           1|\n",
      "|    1|          2|               17.5|           2|\n",
      "|    1|          3|              -27.0|           1|\n",
      "|    1|          5|              -21.0|           2|\n",
      "|    1|          6|  4.333333333333333|           3|\n",
      "|   10|          1|               15.5|           2|\n",
      "|   10|          3|                1.0|           2|\n",
      "|   10|          4|               -6.0|           1|\n",
      "|   10|          5|-3.6666666666666665|           3|\n",
      "|   11|          1|               35.0|           1|\n",
      "|   11|          2|              -23.0|           1|\n",
      "|   11|          4|               -1.0|           2|\n",
      "|   11|          5|               12.0|           1|\n",
      "|   11|          7|               -4.0|           3|\n",
      "|   12|          1|               -1.0|           1|\n",
      "|   12|          2|              -11.5|           2|\n",
      "|   12|          3|               18.5|           2|\n",
      "|   12|          4|                6.0|           1|\n",
      "|   12|          5|                2.0|           2|\n",
      "|   12|          7|               -1.0|           2|\n",
      "+-----+-----------+-------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 8.88 ms, sys: 15 ms, total: 23.9 ms\n",
      "Wall time: 4.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "flightsDf=flightsDf.withColumn('DEPARTURE_DELAY',flightsDf['DEPARTURE_DELAY'].cast(T.DecimalType()))\n",
    "\n",
    "df_op=flightsDf.filter(flightsDf.TAIL_NUMBER =='N407AS').groupby(['MONTH','DAY_OF_WEEK']).agg(F.avg('ARRIVAL_DELAY').alias('MeanArrivalDelay'),F.count('MONTH').alias('NumOfFlights'))\n",
    "\n",
    "df_op.orderBy(df_op.MONTH,df_op.DAY_OF_WEEK).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Spark SQL OPERATION<a class=\"anchor\" id=\"3.3\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+-------------------+------------+\n",
      "|MONTH|DAY_OF_WEEK|   MeanArrivalDelay|NumOfFlights|\n",
      "+-----+-----------+-------------------+------------+\n",
      "|    1|          1|               -6.0|           1|\n",
      "|    1|          2|               17.5|           2|\n",
      "|    1|          3|              -27.0|           1|\n",
      "|    1|          5|              -21.0|           2|\n",
      "|    1|          6|  4.333333333333333|           3|\n",
      "|   10|          1|               15.5|           2|\n",
      "|   10|          3|                1.0|           2|\n",
      "|   10|          4|               -6.0|           1|\n",
      "|   10|          5|-3.6666666666666665|           3|\n",
      "|   11|          1|               35.0|           1|\n",
      "|   11|          2|              -23.0|           1|\n",
      "|   11|          4|               -1.0|           2|\n",
      "|   11|          5|               12.0|           1|\n",
      "|   11|          7|               -4.0|           3|\n",
      "|   12|          1|               -1.0|           1|\n",
      "|   12|          2|              -11.5|           2|\n",
      "|   12|          3|               18.5|           2|\n",
      "|   12|          4|                6.0|           1|\n",
      "|   12|          5|                2.0|           2|\n",
      "|   12|          7|               -1.0|           2|\n",
      "+-----+-----------+-------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 3.87 ms, sys: 1.69 ms, total: 5.57 ms\n",
      "Wall time: 4.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sql_flights_op=spark.sql('''\n",
    "select MONTH,DAY_OF_WEEK,avg(ARRIVAL_DELAY) as MeanArrivalDelay,count(*) as NumOfFlights\n",
    "from sql_flights\n",
    "where TAIL_NUMBER ='N407AS'\n",
    "group by MONTH,DAY_OF_WEEK\n",
    "order by MONTH,DAY_OF_WEEK\n",
    "''')\n",
    "sql_flights_op.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Discussion<a class=\"anchor\" id=\"3.4\"></a>\n",
    "[Back to top](#table)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FIT5202 Assignment 1 SOLUTION.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
